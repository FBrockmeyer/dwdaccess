---
title: "dwdaccess, version 0.0.1"
author: "Friedemann Brockmeyer"
output: github_document
# code_folding: hide
 # md_document:
  #  variant: gfm
  #  preserve_yaml: true
always_allow_html: true
leafletmap: true
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(
  warning = FALSE, message = FALSE, 
  cache = TRUE, fig.path = "man/figures/", fig.align = "center"
)
```

## Disclaimer

I am a Statistician with a passion for sensor data and open data projects. While I have designed and assembled my own weather station (on the basis of the *Raspberry Pi 3*), I also dealt with open data availability of weather data in Germany. A few initial efforts are shown below.

> This site is not intended to share my code - mostly written in *python*, *mySQL*, and *R* - to operate my weather station, and to > save my data on a self-hosted server. At least for the moment. 

## Data

As of `r format(Sys.Date(), "%B %d, %Y")`, the weather and climate data for Germany can be found at the [open data server](https://opendata.dwd.de/climate_environment/CDC/) provided by ["Deutscher Wetterdienst"](https://www.dwd.de/EN/Home/home_node.html), commonly abbreviated as *DWD*. 

To access relevant data conveniently, we wrapped simple functions in a tiny package called `{dwdaccess}`. The usage will be demonstrated by telling a little story originated from a trivial conversation I had with a friend at a lake on a hot summer day in August 2023. 

> There exist other *R* packages to handle data from DWD like ["rdwd"](https://bookdown.org/brry/rdwd/). Those are beyond the scope > of this project. 

## Installation

One can install the development version of `{dwdaccess}` from [GitHub](https://github.com/FBrockmeyer/dwdaccess) with:

```{r install, echo = TRUE}
if(!require(devtools)) install.packages("devtools")
devtools::install_github("FBrockmeyer/dwdaccess")
library(dwdaccess)
```

The development of a full and competitive package available via CRAN is not planned yet. 

## Example: *A tropical night* 

The lake we met at was the famous [Wannsee](https://www.openstreetmap.org/search?query=Wannsee#map=12/52.4341/13.1992). 
To retrieve the latitude and longitude coordinates of any location we wrote a function `address_to_lonlat()` which translates any character string like `"Wannsee Berlin"` to a numeric vector containing longitude and latitude coordinates. To do so, the function relies on an API service from [Open Street Map](https://www.openstreetmap.org/). With *RStudio*'s viewer we can display the locations on a variety of maps. Particularly interesting for the development of a *shiny app* (TODO). 

```{r map, results='hide', fig.show='hide', echo = TRUE}
{
  library(leaflet)
  library(leaflegend)
}

kladow <- address_to_lonlat("Kladow Berlin")

leaflet() |>
  addTiles() |>
  flyTo(lng = kladow["longitude"],
        lat = kladow["latitude"], 
        zoom = 11) |>
  addMiniMap(width = 150L, height = 150L)
```

> The output from the *code chunk* above cannot be presented on Github, since support for *java*-driven applications like *leaflet* is still missing. Come back later to see an update.  

Besides the location of interest, we need the locations of all weather stations operated and affiliated by DWD to identify relevant stations close by. The function `dwd_stations()` returns a list of weather stations. The list is on-line available, click [here](https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/daily/kl/recent/KL_Tageswerte_Beschreibung_Stationen.txt). Finally, with `distance_between()` we are able to calculate the distance between the inserted location, *Kladow*, a village situated on the lake, and the nearest weather stations in meters: 

```{r ex1, echo = TRUE}
distance_between(stations = dwd_stations(),
                 location = address_to_lonlat(address = "Kladow Berlin")) |>
                 # everything from here on is for styling purposes only
  head() |> 
  kable(col.names = c("id", "start_date", "end_date", "stations_height", "name", "geometry", "distance")) 
```
<!-- https://bookdown.org/yihui/rmarkdown-cookbook/kable.html -->

> Throughout this introduction the commands `kable()` and, later, `t() |> kable()` are used to style the output. 
> `kable()` is exported from package [`{knitr}`](https://bookdown.org/yihui/rmarkdown-cookbook/kable.html). 

The wrapper `zip_urls()` scraps the information found under links of [this form](https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/hourly/air_temperature/recent/), e.g.

```{r ex1_continued0, echo = TRUE}
recent_temp <- zip_urls(
  link = "https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/hourly/air_temperature/recent/") 
historical_temp <- zip_urls(
  link = "https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/hourly/air_temperature/historical/")
```

and is mainly designed to collect all links to available *.zip*-files. A link for each station/id. The function is not restricted to data on an hourly basis. It works with [other time intervals between measurements](https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/) as well. Let's store the `id`s of the five closest weather stations (A) and check if data, i.e., links to *.zip*-files, are indeed available (B):

```{r ex1_continued1, echo = TRUE}
# (A)
nearest5stations <- distance_between(stations = dwd_stations(),
                                     location = address_to_lonlat(address = "Kladow Berlin")
                                     )$Stations_id[1L:5L]
# (B)
recent_temp[recent_temp$id %in% nearest5stations, ] |> kable()
historical_temp[historical_temp$id %in% nearest5stations, ] |> kable()
```

It looks like the station with `id` $03987$ is the only out of the five closest stations providing data. Does the data for recent and historical records come from the same station? 

```{r ex1_continued1.1, echo = TRUE}
recent_temp[recent_temp$id %in% nearest5stations, ]$id == 
  historical_temp[historical_temp$id %in% nearest5stations, ]$id
```

Yes. Which station name corresponds to the `id`? 

```{r ex1_continued2, echo = TRUE}
dwd_stations()[
  which(dwd_stations()$Stations_id == recent_temp[recent_temp$id %in% nearest5stations, ]$id), ] |>
  kable(col.names = c("id", "start_date", "end_date", "stations_height", "name", "geometry", "distance")) 
```
The weather station on the grounds of the *University of Potsdam* it is, click [here](https://www.openstreetmap.org/search?whereami=1&query=52.38124%2C13.06212#map=19/52.38124/13.06212) to see the location. As we have now identified potential data, we continue with the download of recent (air) temperature (and humidity) data on an hourly basis. Additionally, we download all historical data that is available. 

> A thorough documentation can be found [here](https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/hourly/air_temperature/). A complete list of available variables can be obtained from [here](https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/hourly/). We assume that the download function `download_data()` can also be used for other sub folders than *air_temperature* and *precipitation*. 

The below code demonstrates the utilisation of `download_data()` to access data from a certain weather station. The function can also be used to download data from several stations at once. For this, the input data frame `job` needs to contain several station ids. After the download process is complete, we use several `{data.table}` functions to rename and modify the data in the fastest possible manner. 
You can ignore the surrounding if-clause and its purposes. 

```{r, message=FALSE, ex1_continued3, echo = TRUE, comment=""}
# Code in if-clause runs only once per R session. This is intended behaviour.
if(exists("hasRun") == FALSE) {
  # Download weather data 
  recent_data <- download_data(
    job = recent_temp[recent_temp$id %in% nearest5stations, ],
    cleanup = TRUE)
  historical_data <- download_data(
    job = historical_temp[historical_temp$id %in% nearest5stations, ],
    cleanup = TRUE)
  # Modify and rename 
  {
    library(data.table)
  }
  data <- data.table::merge.data.table(x = data.table::setDT(recent_data),
                                       y = data.table::setDT(historical_data), 
                                       all = TRUE)
  # Clean-up environment 
  rm(recent_data, historical_data)
  # Renaming
  data <- setNames(object = data, 
                   nm = c("id", "datetime", "quality9", 
                          "temperature", "humidity", "eor"))
  # Change character variable containing date information to POSIXct (datetime)
  data[, datetime := as.POSIXct(x = as.character(datetime), 
                            format = "%Y%m%d%H", 
                            origin = Sys.timezone())]
  # Pad id with zeros; nchar == 5
  data[, id := sprintf("%05s", id)]
  # Replace missing values with R-like NA's
  for(col in names(data)) data.table::set(data, 
                                          i = which(data[[col]] == -999.000), 
                                          j = col, 
                                          value = NA)
  hasRun <- TRUE 
}
```

The data is now downloaded, merged and prepared in a very *R*-like fashion. The time has come to do simple explanatory analysis. How many observations and variables did we get?  

```{r ex1_continued4.1, echo = TRUE}
dim(data) |> kable()
```

More than a million observations, and six variables, distributed over 

```{r ex1_continued4.2, echo = TRUE}
difftime(
  time1 = max(data$datetime, na.rm = TRUE), 
  time2 = min(data$datetime, na.rm = TRUE), 
  tz = Sys.timezone(), units = "days") |> kable()
```

roughly $130.71$ years. That is the number of days $47,7743.87$ divided by $365.25$. Similarly relevant is the share of observations with non-missing (air) temperature values: 

```{r ex1_continued5, echo = TRUE}
sum(complete.cases(data$temperature)) / nrow(data) 
```

This figure is impressively high. 

Coming back to the trivial conversation. We spoke about the extreme heat during these days in the middle of August 2023. One mentioned: "We have a **tropical night**.". *Meteorologists* define those as **nights where the lowest (air) temperature between 6 p.m. and 6 a.m. does not fall under 20°C**. By the way, (air) temperature is commonly measured at a height of two meters above sea level, see, e.g. the [DWD documentation](https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/hourly/air_temperature/DESCRIPTION_obsgermany_climate_hourly_air_temperature_en.pdf). We would now like to know whether he was correct in stating that.

To increase comprehensibility, we switch to `{dplyr}` syntax. Although (moderately) slower in big data applications, it is more widely used in applied science than `{data.table}`. First, we calculate a few more variables `year`, `month`, and `date` to simplify filtering (1). Second, we store the data under the name `example` to reduce length of code in subsequent `code chunks` (2). We, then, *subset* the data to get the relevant month: August 2023 (3). Essentially, we calculate an indicator variable [`tn20GT`](https://en.wikipedia.org/wiki/Tropical_night) which is `TRUE` if a certain night meets the definition and `FALSE` otherwise (4).

```{r ex1_continued6, echo = TRUE}
library(dplyr); library(lubridate)
# (1) + (2)
example <- data |>
  mutate(year = lubridate::year(datetime),
         month = lubridate::month(datetime), 
         date = lubridate::date(datetime)) 
# (3)
example |>
  filter(year == 2023L & 
           datetime >= as.POSIXct("2023073118", format = "%Y%m%d%H", origin = Sys.timezone()) & 
           datetime <= as.POSIXct("2023083106", format = "%Y%m%d%H", origin = Sys.timezone())
         ) |>
# (4)
  # shifted time ranges 
  mutate(shifted_start = lubridate::as_date(datetime - lubridate::hours(18))) |>
  summarise(tn20GT = all(temperature >= 20L), .by = shifted_start) |>
  count(tn20GT) |> kable()
```

For each day, to decide whether or not a night was tropical the routine considers the previous night instead of the upcoming one. This is a matter of definition. As a consequence, $6$ hours of July 31, 2023 need to be taken into account. Similarly, the filtering ends on `r as.POSIXct("2023083106", format = "%Y%m%d%H", origin = Sys.timezone())`, meaning August 31, 2023 at 6 a.m., such that the (air) temperatures on the last evening of August 2023 are ignored as those only influence the calculation w.r.t. September 1, 2023. Which night was tropical? 

```{r ex1_continued7, echo = TRUE}
example |>
  filter(year == 2023L & 
           # read "2023073118" as July 30, 2023 at 6 p.m. 
           datetime >= as.POSIXct("2023073118", format = "%Y%m%d%H", origin = Sys.timezone()) & 
           datetime <= as.POSIXct("2023083106", format = "%Y%m%d%H", origin = Sys.timezone())
         ) |>
  mutate(shifted_start = lubridate::as_date(datetime - lubridate::hours(18))) |>
  summarise(tn20GT = all(temperature >= 20L), .by = shifted_start) |>
  filter(tn20GT == 1L) |> kable()
```

> `shifted_start` is an auxiliary variable, created to calculate `tn20GT`, and slightly misleading in terms of interpretation. Due to the shift, we need to add one day to the date under `shifted_start`:  

```{r ex1_continued8, echo = TRUE}
example |>
  filter(year == 2023L & 
           datetime >= as.POSIXct("2023081918", format = "%Y%m%d%H", origin = Sys.timezone()) & 
           datetime <= as.POSIXct("2023082006", format = "%Y%m%d%H", origin = Sys.timezone())
         ) |> 
  select(id, datetime, temperature, humidity) |>
  kable()
```

All records between $6$ p.m. and $6$ a.m. are greater than $20°C$. **Therefore, the night previous to the day August 20, 2023 was tropical. He was right.**

The [German version](https://de.wikipedia.org/wiki/Tropennacht) of the Wikipedia article "*Tropical night*" is interesting. Among other things, it is explained that the [weather station of the Meteorological Institute (LMU) in Munich](https://www.meteorologie.lmu.de/ueber_uns/kontakt/index.html) recorded a yearly average of $1.7$ *tropical nights* between 1982 and 2002. Worrisome, between 2003 and 2018 this number increased to $5.25$. Unequal periods of time, $20$ and $15$ years as well as the selection of the starting years appear questionable and need to be investigated. Scientifically unsound at first glance. However, the following code calculates those numbers for the weather station located in *Potsdam*: 

```{r ex1_continued9, echo = TRUE}
example |>
  filter(year %in% 1982L:2002L) |>
  mutate(shifted_start = lubridate::as_date(datetime - lubridate::hours(18L))) |>
  summarise(tn20GT = all(temperature >= 20L), .by = c(shifted_start, year)) |>
  select(year, tn20GT) |>
  summarise(tn20GT_total = sum(tn20GT), .by = year) |> t() |> kable()
```

In total $13$ *tropical nights* are recorded, resulting in an average of $\sim 0.62$ *tropical nights* per year between 1982 and 2002. 1994 is striking with four occurrences. For the time period 2003-2018 the result looks as follows:

```{r ex1_continued10, echo = TRUE}
example |>
  filter(year %in% 2003L:2018L) |>
  mutate(shifted_start = lubridate::as_date(datetime - lubridate::hours(18L))) |>
  summarise(tn20GT = all(temperature >= 20L), .by = c(shifted_start, year)) |>
  select(year, tn20GT) |>
  summarise(tn20GT_total = sum(tn20GT), .by = year) |> t() |> kable()
```

For this span of years, $36$ *tropical nights* are recorded. The corresponding average is $2.25$. 
We observe eight *tropical nights* in 2018. My mother and grandmother regularly remind others of the heat in 1994. I wonder if they remember 2018 in the same way?

```{r, echo=FALSE, fig.cap = "How the author escaped the heat in 1994.", fig.align = "center", , fig.asp = 0.25}
knitr::include_graphics("images/IMG_2380.png")
```

What about the recent years? 

```{r ex1_continued11, echo = TRUE}
example |>
  filter(year %in% 2019L:2023L) |>
  mutate(shifted_start = lubridate::as_date(datetime - lubridate::hours(18L))) |>
  summarise(tn20GT = all(temperature >= 20L), .by = c(shifted_start, year)) |>
  select(year, tn20GT) |>
  summarise(tn20GT_total = sum(tn20GT), .by = year) |> t() |> kable()
```

The Wikipedia article I have mentioned earlier provides multiple definitions: 

* desert day $:= T_{max} \geq 35°C$,
* hot day $:= T_{max} \geq 30°C$, 
* summer day $:= T_{max} \geq 25°C$,
* heating day $:= T_{med} < 12°C$, 
* vegetation day $:= T_{med} \geq 5°C$,
* frosty day $:= T_{min} < 0°C$, and 
* icy day $:= T_{max} < 0°C$, where 

T $:=$ temperature, max $:=$ maximum, min $:=$ minimum, and med $:=$ median. 

For the given span of years, the total amount of days per year falling into each day category can be visualised by  

```{r figures, fig.asp = 1.25}
library(sysfonts); library(showtext); library(ggplot2)
font_add_google("Fuzzy Bubbles")
showtext_auto()

example2 <- data |>
  mutate(year = lubridate::year(datetime),
         month = lubridate::month(datetime), 
         date = lubridate::date(datetime)) |> 
  select(-datetime) |> 
  summarise(max_temp = max(temperature, na.rm = TRUE), 
         min_temp = min(temperature, na.rm = TRUE), 
         med_temp = median(temperature, na.rm = TRUE),
         avg_temp = mean(temperature, na.rm = TRUE), 
         .by = c(date, year))

example2 |> 
  # https://de.wikipedia.org/wiki/Wüstentag_(Meteorologie)
  summarise(desert_day = sum(max_temp >= 35L, na.rm = TRUE), 
            hot_day = sum(max_temp >= 30L, na.rm = TRUE),
            summer_day = sum(max_temp >= 25L, na.rm = TRUE),
            heating_day = sum(med_temp < 12L, na.rm = TRUE),
            vegetation_day = sum(med_temp >= 5L, na.rm = TRUE),
            frosty_day = sum(min_temp < 0L, na.rm = TRUE),
            icy_day = sum(max_temp < 0L, na.rm = TRUE), 
            .by = year) |> 
  filter(!is.na(year)) |>
  tidyr::pivot_longer(cols = -year, 
                      names_to = "day", 
                      values_to = "count") |>
  
  ggplot(aes(y = count, x = year)) +
  geom_bar(stat = "identity") +
  geom_smooth(stat = "smooth", method = "loess", col = "red", 
              se = TRUE, na.rm = TRUE, linewidth = .5) +
  facet_wrap(~factor(day, levels = 
                       c("desert_day", "hot_day", "summer_day", 
                         "heating_day", "vegetation_day", 
                         "frosty_day", "icy_day")), 
             nrow = 3L, scales = "free") +
  scale_y_continuous(expand = c(0L, 0L)) +
  scale_x_continuous(breaks = seq(from = min(example2$year, na.rm = TRUE), 
                                  to = max(example2$year, na.rm = TRUE), 
                                  by = 10L), 
                     expand = c(0L, 0L)) +
  labs(main = "Yearly counts of days per category.", 
       x = "") +
  ggthemes::theme_base() + 
  theme(axis.text.x = element_text(angle = 90L, size = 7L), 
        text = element_text(family = "Fuzzy Bubbles"))
```


>Note, years with missing data cause white space inside the figures. 

## Example: *On Precipitation*

**Please note. More explanation will be added with future versions.**

Until now, we only experimented with temperature data. We continue with the download of rainfall (precipitation) data available by running the same routine as before:

```{r, message=FALSE, results='hide'}
recent_rain <- zip_urls(
  link = 
    "https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/hourly/precipitation/recent/") 
historical_rain <- zip_urls(
  link = 
    "https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/hourly/precipitation/historical/")

## checks
# "03987" %in% recent_rain$id
# "03987" %in% historical_rain$id

if(exists("hasRun2") == FALSE) {
  recent_data <- download_data(
    job = recent_rain[recent_rain$id == "03987", ],
    cleanup = TRUE)
  historical_data <- download_data(
    job = historical_rain[historical_rain$id == "03987", ],
    cleanup = TRUE)
  rf <- data.table::merge.data.table(x = data.table::setDT(recent_data),
                                     y = data.table::setDT(historical_data), 
                                     all = TRUE)
  rm(recent_data, historical_data)
  # Renaming (modified)
  rf <- rf[, c("STATIONS_ID", "MESS_DATUM", "QN_8", "R1")]
  rf <- setNames(object = rf, 
                 nm = c("id", "datetime", 
                        "quality8", "precipitation"))
  rf[, datetime := as.POSIXct(x = as.character(datetime), 
                              format = "%Y%m%d%H", 
                              origin = Sys.timezone())]
  rf[, id := sprintf("%05s", id)]
  for(col in names(rf)) data.table::set(rf, 
                                        i = which(rf[[col]] == -999.000), 
                                        j = col, 
                                        value = NA)
  hasRun2 <- TRUE 
}
```

What did we get?  

```{r}
rf |> head() |> kable()
min(rf$datetime, na.rm = TRUE); max(rf$datetime, na.rm = TRUE)
dim(rf) |> kable()
```

Visualising the last ten years by means of *monthly accumulated rainfall* (`monthly_rainfall`):

```{r, fig.asp = 1.5}
rf |>
  mutate(year = lubridate::year(datetime),
         month = lubridate::month(datetime)) |>
  select(-datetime) |> 
  summarise(monthly_rainfall = sum(precipitation, na.rm = TRUE), 
            .by = c(year, month)) |>
  filter(!is.na(year) & year %in% 2013L:2022L) |>
  
  ggplot(aes(x = month, y = monthly_rainfall)) +
  geom_bar(stat = "identity", fill = "lightblue") +
  facet_wrap(~factor(year, levels = 2022L:2013L), 
             scales = "free", ncol = 3L) +
  scale_x_continuous(breaks = 1L:12L,
                     labels = c('Jan', 'Feb', 'Mar', 
                                'Apr', 'May', 'Jun', 
                                'Jul', 'Aug', 'Sep', 
                                'Oct', 'Nov', 'Dez'), 
                     expand = c(0L, 0L)) +
  scale_y_continuous(expand = c(0L, 0L)) +
  labs(y = expression(paste("rainfall in ", frac(mm, month))),
       x = "") +
  ggthemes::theme_base() + 
  theme(axis.text.x = element_text(angle = 90L, size = 7L))
```

>Note. As there arise errors when `text = element_text(family = "Fuzzy Bubbles")` is added to `theme()`, this line is currently not used to style the figures with a fancy font.  

Extracting the years with minimal and maximal amounts of *rainfall*:

```{r}
rf |>
  mutate(year = lubridate::year(datetime),
         month = lubridate::month(datetime)) |>
  select(-datetime) |> 
  summarise(monthly_rainfall = sum(precipitation, na.rm = TRUE), 
            .by = c(year, month)) |>
  filter(!is.na(year) & year >= 2010L) |>
  summarise(yearly_rainfall = sum(monthly_rainfall), 
            .by = year) |>
  arrange(desc(yearly_rainfall)) |> kable()
```

Interesting! The wettest year is followed by the most driest one.

### Arranging climograph for the most and less rainy years 

Data handling: filtering and merging accordingly. 

```{r}
x <- rf |>
  mutate(year = lubridate::year(datetime),
         month = lubridate::month(datetime)) |>
  filter(year %in% 2017L:2018L)

y <- data |>
  mutate(year = lubridate::year(datetime),
         month = lubridate::month(datetime)) |>
  filter(year %in% 2017L:2018L)

xy <- data.table::merge.data.table(x = x[, -"quality8"], 
                                   y = y[, c("datetime", "temperature", "humidity")], 
                                   by = "datetime")
```

Build a plot with two y-axes. Left: *monthly amount of rainfall*; right: *average monthly temperature*.

```{r, fig.asp = 1.25}
climograph_data <- 
  xy |>
  select(-datetime) |>
  summarise(monthly_rainfall = sum(precipitation, na.rm = TRUE),
            monthly_avg_temp = mean(temperature, na.rm = TRUE),
            .by = c(year, month)) 

ylim_1st <- c(0L, 220L)  
ylim_2nd <- c(-2L, 23L)  
b <- diff(ylim_1st) / diff(ylim_2nd)
a <- ylim_1st[[1L]] - b * ylim_2nd[[1L]]

climograph_data |>
  ggplot(aes(x = month, y = monthly_rainfall)) +
  geom_col(fill = "lightblue") +
  geom_text(aes(label = monthly_rainfall), vjust = -.25, size = 3L) +
  geom_point(aes(y = a + monthly_avg_temp * b), shape = 15L, col = "red", size = 2L) +
  geom_text(aes(y = a + monthly_avg_temp * b, label = round(x = monthly_avg_temp, digits = 1L)), 
            col = "red", size = 3L, hjust = .8, vjust = -1L) +
  geom_line(aes(y = a + monthly_avg_temp * b), col = "red") +
  facet_wrap(vars(factor(year))) +
  scale_y_continuous(name = "precipitation [mm]", 
                     sec.axis = sec_axis(~ (. - a) / b, name = "temperature [°C]")) +
  scale_x_continuous(breaks = 1L:12L,
                     labels = 
                       c('Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 
                         'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dez')) +
  labs(title = "Climograph", subtitle = "for Potsdam", x = "") +
  ggthemes::theme_base() + 
  theme(axis.text.x = element_text(angle = 90L, size = 7L))
```

>Note again. As there arise errors when `text = element_text(family = "Fuzzy Bubbles")` is added to `theme()`, this line is currently not used to style the figures with a fancy font.  

More to come. Come back later. 




